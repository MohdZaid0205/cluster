{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# User Entity Benchmarking\n",
                "\n",
                "This notebook benchmarks the performance of a **Monolithic User** table versus a **Fragmented** approach (Auth vs Profile).\n",
                "\n",
                "## Trade-offs Tested\n",
                "1.  **Write Penalty**: Fragmentation requires multiple writes (Auth + Profile), which should be significantly slower.\n",
                "2.  **Read Optimization (Feed Author)**: Fetching just the `name` and `image` for a list of authors (common in feeds) should be faster on the thinner `UserProfile` table vs the fat `UserMonolith`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (quietly)\n",
                "# !pip install sqlmodel faker > /dev/null 2>&1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import time\n",
                "import random\n",
                "import os\n",
                "from typing import Optional\n",
                "from sqlmodel import Field, SQLModel, create_engine, Session, select, func\n",
                "from faker import Faker\n",
                "from enum import Enum\n",
                "from uuid import UUID, uuid4\n",
                "from datetime import datetime\n",
                "\n",
                "# Ensure temp directory exists\n",
                "os.makedirs(\"temp/db\", exist_ok=True)\n",
                "\n",
                "DATABASE_URL = \"sqlite:///temp/db/benchmarking_user.db\"\n",
                "engine = create_engine(DATABASE_URL, echo=False)\n",
                "fake = Faker()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Monolithic Architecture\n",
                "\n",
                "Single table with all columns.\n",
                "\n",
                "### Schema\n",
                "```sql\n",
                "CREATE TABLE usermonolith (\n",
                "    uid CHAR(36) PRIMARY KEY,\n",
                "    email VARCHAR(255) UNIQUE INDEX,\n",
                "    password_hash VARCHAR(255),  -- Heavy/Secret\n",
                "    role VARCHAR(50),\n",
                "    is_verified BOOLEAN,\n",
                "    name VARCHAR(255),\n",
                "    phone VARCHAR(255),\n",
                "    location VARCHAR(255),\n",
                "    bio TEXT,                    -- Heavy\n",
                "    profile_image VARCHAR(255),\n",
                "    created_at DATETIME,\n",
                "    last_active DATETIME\n",
                ");\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "class UserRole(str, Enum):\n",
                "    GUEST = \"GUEST\"\n",
                "    MEMBER = \"MEMBER\"\n",
                "    ADMIN = \"ADMIN\"\n",
                "\n",
                "class UserMonolith(SQLModel, table=True):\n",
                "    uid: UUID = Field(default_factory=uuid4, primary_key=True)\n",
                "    email: str = Field(index=True, unique=True)  # Auth\n",
                "    password_hash: str  # Auth\n",
                "    role: UserRole = Field(default=UserRole.MEMBER)  # Auth\n",
                "    is_verified: bool = Field(default=False)  # Auth\n",
                "    name: str  # Profile\n",
                "    phone: Optional[str] = Field(default=None)  # Profile\n",
                "    location: Optional[str] = Field(default=None)  # Profile\n",
                "    bio: Optional[str] = Field(default=None)  # Profile\n",
                "    profile_image: Optional[str] = Field(default=None)  # Profile\n",
                "    created_at: datetime = Field(default_factory=datetime.utcnow)  # Meta\n",
                "    last_active: datetime = Field(default_factory=datetime.utcnow)  # Meta"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Fragmented Architecture\n",
                "\n",
                "Split into `UserAuth` (Credentials) and `UserProfile` (Public Data). This isolates heavy/unused columns from specific access patterns.\n",
                "\n",
                "### Schema\n",
                "```sql\n",
                "CREATE TABLE userauth (\n",
                "    uid CHAR(36) PRIMARY KEY,\n",
                "    email VARCHAR(255) UNIQUE INDEX,\n",
                "    password_hash VARCHAR(255),\n",
                "    role VARCHAR(50),\n",
                "    is_verified BOOLEAN\n",
                ");\n",
                "\n",
                "CREATE TABLE userprofile (\n",
                "    uid CHAR(36) PRIMARY KEY FOREIGN KEY(userauth.uid),\n",
                "    name VARCHAR(255),           -- Needed for Feed/Core\n",
                "    profile_image VARCHAR(255),  -- Needed for Feed/Core\n",
                "    phone VARCHAR(255),\n",
                "    location VARCHAR(255),\n",
                "    bio TEXT,\n",
                "    created_at DATETIME,\n",
                "    last_active DATETIME\n",
                ");\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "class UserAuth(SQLModel, table=True):\n",
                "    uid: UUID = Field(default_factory=uuid4, primary_key=True)\n",
                "    email: str = Field(index=True, unique=True)\n",
                "    password_hash: str\n",
                "    role: UserRole = Field(default=UserRole.MEMBER)\n",
                "    is_verified: bool = Field(default=False)\n",
                "\n",
                "class UserProfile(SQLModel, table=True):\n",
                "    uid: UUID = Field(primary_key=True, foreign_key=\"userauth.uid\")\n",
                "    name: str\n",
                "    profile_image: Optional[str]\n",
                "    phone: Optional[str]\n",
                "    location: Optional[str]\n",
                "    bio: Optional[str]\n",
                "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
                "    last_active: datetime = Field(default_factory=datetime.utcnow)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating 10000 users...\n"
                    ]
                }
            ],
            "source": [
                "ENTRY_COUNT = 10_000\n",
                "print(f\"Generating {ENTRY_COUNT} users...\")\n",
                "\n",
                "# Clear existing tables if needed\n",
                "SQLModel.metadata.drop_all(engine)\n",
                "SQLModel.metadata.create_all(engine)\n",
                "\n",
                "users_data = []\n",
                "for _ in range(ENTRY_COUNT):\n",
                "    users_data.append({\n",
                "        \"email\": fake.unique.email(),\n",
                "        \"password_hash\": fake.sha256(),\n",
                "        \"role\": random.choice(list(UserRole)),\n",
                "        \"is_verified\": fake.boolean(),\n",
                "        \"name\": fake.name(),\n",
                "        \"phone\": fake.phone_number(),\n",
                "        \"location\": fake.city(),\n",
                "        \"bio\": fake.text(),\n",
                "        \"profile_image\": fake.image_url(),\n",
                "        \"created_at\": fake.date_time_this_year(),\n",
                "        \"last_active\": fake.date_time_this_year()\n",
                "    })"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Benchmarks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Benchmarking Insertions (WRITE PENALTY)...\n",
                        "Monolith Insert Time: 1.0853s\n",
                        "Fragmented Insert Time: 4.2281s\n",
                        "RESULT: Fragmentation is 3.9x slower to write.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Benchmarking Insertions (WRITE PENALTY)...\")\n",
                "\n",
                "# Benchmark Monolith Insert\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    for data in users_data:\n",
                "        user = UserMonolith(**data)\n",
                "        session.add(user)\n",
                "    session.commit()\n",
                "mono_insert_time = time.perf_counter() - start_time\n",
                "\n",
                "# Benchmark Fragmented Insert\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    for data in users_data:\n",
                "        # Split data\n",
                "        auth_data = {k: v for k, v in data.items() if k in UserAuth.model_fields}\n",
                "        profile_data = {k: v for k, v in data.items() if k in UserProfile.model_fields}\n",
                "        \n",
                "        auth = UserAuth(**auth_data)\n",
                "        session.add(auth)\n",
                "        session.flush() # Get UID\n",
                "        \n",
                "        profile = UserProfile(uid=auth.uid, **profile_data)\n",
                "        session.add(profile)\n",
                "    session.commit()\n",
                "frag_insert_time = time.perf_counter() - start_time\n",
                "\n",
                "print(f\"Monolith Insert Time: {mono_insert_time:.4f}s\")\n",
                "print(f\"Fragmented Insert Time: {frag_insert_time:.4f}s\")\n",
                "print(f\"RESULT: Fragmentation is {frag_insert_time/mono_insert_time:.1f}x slower to write.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Benchmarking Feed Author Resolution (READ OPTIMIZATION)...\n",
                        "Monolith Author Lookup (1000 ops): 0.2984s\n",
                        "Fragmented Author Lookup (1000 ops): 0.2097s\n"
                    ]
                }
            ],
            "source": [
                "print(\"Benchmarking Feed Author Resolution (READ OPTIMIZATION)...\")\n",
                "# Scenario: Loading a feed of 20 posts, we need to resolve the Author Name & Image for 20 UIDs.\n",
                "SAMPLE_SIZE = 1000  # Running 1000 author lookups to average the noise\n",
                "target_uids = [u.uid for u in session.exec(select(UserAuth).limit(SAMPLE_SIZE)).all()]\n",
                "\n",
                "# Monolith Lookup\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    for uid in target_uids:\n",
                "        # Must scan wider table\n",
                "        session.exec(select(UserMonolith.name, UserMonolith.profile_image).where(UserMonolith.uid == uid)).first()\n",
                "mono_read_time = time.perf_counter() - start_time\n",
                "\n",
                "# Fragmented Lookup\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    for uid in target_uids:\n",
                "        # Scan thinner table (UserProfile)\n",
                "        session.exec(select(UserProfile.name, UserProfile.profile_image).where(UserProfile.uid == uid)).first()\n",
                "frag_read_time = time.perf_counter() - start_time\n",
                "\n",
                "print(f\"Monolith Author Lookup ({SAMPLE_SIZE} ops): {mono_read_time:.4f}s\")\n",
                "print(f\"Fragmented Author Lookup ({SAMPLE_SIZE} ops): {frag_read_time:.4f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Fragmented Read is 1.42x faster than Monolith for Feed Author Resolution.\n"
                    ]
                }
            ],
            "source": [
                "# Justification\n",
                "ratio = mono_read_time / frag_read_time if frag_read_time > 0 else 0\n",
                "print(f\"\\nFragmented Read is {ratio:.2f}x faster than Monolith for Feed Author Resolution.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
