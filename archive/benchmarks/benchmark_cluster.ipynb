{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Cluster Entity Benchmarking\n",
                "\n",
                "This notebook benchmarks the performance of a **Monolithic Cluster** table versus a **Fragmented** approach (Core vs Info vs Stats).\n",
                "\n",
                "## Hypothesis\n",
                "Clusters have high read traffic for discovery (Name/Image) and high write traffic for stats (Member Count). Separating these should improve concurrency and cache locality."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (quietly)\n",
                "# !pip install sqlmodel faker > /dev/null 2>&1"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sqlmodel import Field, SQLModel, create_engine, Session, select\n",
                "from faker import Faker\n",
                "import time\n",
                "import random\n",
                "import os\n",
                "from uuid import UUID, uuid4\n",
                "from datetime import datetime\n",
                "from typing import Optional\n",
                "\n",
                "os.makedirs(\"temp/db\", exist_ok=True)\n",
                "DATABASE_URL = \"sqlite:///temp/db/benchmarking_cluster.db\"\n",
                "engine = create_engine(DATABASE_URL, echo=False)\n",
                "fake = Faker()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Monolithic Architecture\n",
                "\n",
                "All cluster data (`name`, `description`, `stats`, `settings`) is stored in one table.\n",
                "\n",
                "### Schema\n",
                "```sql\n",
                "CREATE TABLE clustermonolith (\n",
                "    cid CHAR(36) PRIMARY KEY,\n",
                "    name VARCHAR(255) INDEX,\n",
                "    topic VARCHAR(255) INDEX,\n",
                "    description TEXT,\n",
                "    owner_id CHAR(36),\n",
                "    created_at DATETIME,\n",
                "    image_url VARCHAR(255),\n",
                "    is_private BOOLEAN,\n",
                "    member_count INTEGER,\n",
                "    post_count INTEGER,\n",
                "    rules TEXT,\n",
                "    settings TEXT\n",
                ");\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ClusterMonolith(SQLModel, table=True):\n",
                "    cid: UUID = Field(default_factory=uuid4, primary_key=True)\n",
                "    name: str = Field(index=True)\n",
                "    topic: str = Field(index=True)\n",
                "    description: str\n",
                "    owner_id: UUID\n",
                "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
                "    image_url: Optional[str] = None\n",
                "    is_private: bool = False\n",
                "    member_count: int = 0\n",
                "    post_count: int = 0\n",
                "    rules: Optional[str] = None\n",
                "    settings: Optional[str] = None"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Fragmented Architecture\n",
                "\n",
                "Split into:\n",
                "*   `ClusterCore`: Lightweight, frequent reads (List/Discovery).\n",
                "*   `ClusterInfo`: Heavy text, on-demand reads (Details).\n",
                "*   `ClusterStats`: High frequency writes (Member/Post counts).\n",
                "\n",
                "### Schema\n",
                "```sql\n",
                "CREATE TABLE clustercore (\n",
                "    cid CHAR(36) PRIMARY KEY,\n",
                "    name VARCHAR(255) INDEX,\n",
                "    topic VARCHAR(255) INDEX,\n",
                "    image_url VARCHAR(255),\n",
                "    is_private BOOLEAN\n",
                ");\n",
                "\n",
                "CREATE TABLE clusterinfo (\n",
                "    cid CHAR(36) PRIMARY KEY FOREIGN KEY(clustercore.cid),\n",
                "    description TEXT,\n",
                "    owner_id CHAR(36),\n",
                "    created_at DATETIME,\n",
                "    rules TEXT,\n",
                "    settings TEXT\n",
                ");\n",
                "\n",
                "CREATE TABLE clusterstats (\n",
                "    cid CHAR(36) PRIMARY KEY FOREIGN KEY(clustercore.cid),\n",
                "    member_count INTEGER,\n",
                "    post_count INTEGER\n",
                ");\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ClusterCore(SQLModel, table=True):\n",
                "    cid: UUID = Field(default_factory=uuid4, primary_key=True)\n",
                "    name: str = Field(index=True)\n",
                "    topic: str = Field(index=True)\n",
                "    image_url: Optional[str]\n",
                "    is_private: bool = False\n",
                "\n",
                "class ClusterInfo(SQLModel, table=True):\n",
                "    cid: UUID = Field(primary_key=True, foreign_key=\"clustercore.cid\")\n",
                "    description: str\n",
                "    owner_id: UUID\n",
                "    created_at: datetime = Field(default_factory=datetime.utcnow)\n",
                "    rules: Optional[str]\n",
                "    settings: Optional[str]\n",
                "\n",
                "class ClusterStats(SQLModel, table=True):\n",
                "    cid: UUID = Field(primary_key=True, foreign_key=\"clustercore.cid\")\n",
                "    member_count: int = 0\n",
                "    post_count: int = 0"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Data Generation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ENTRY_COUNT = 5_000\n",
                "print(f\"Generating {ENTRY_COUNT} clusters...\")\n",
                "\n",
                "# Clear existing\n",
                "SQLModel.metadata.drop_all(engine)\n",
                "SQLModel.metadata.create_all(engine)\n",
                "\n",
                "clusters_data = []\n",
                "for _ in range(ENTRY_COUNT):\n",
                "    clusters_data.append({\n",
                "        \"name\": fake.company(),\n",
                "        \"topic\": fake.word(),\n",
                "        \"description\": fake.text(),\n",
                "        \"owner_id\": uuid4(),\n",
                "        \"image_url\": fake.image_url(),\n",
                "        \"is_private\": fake.boolean(),\n",
                "        \"member_count\": random.randint(0, 10000),\n",
                "        \"post_count\": random.randint(0, 5000),\n",
                "        \"rules\": fake.text(),\n",
                "        \"settings\": \"{}\"\n",
                "    })"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Populate Monolith\n",
                "with Session(engine) as session:\n",
                "    for data in clusters_data:\n",
                "        session.add(ClusterMonolith(**data))\n",
                "    session.commit()\n",
                "\n",
                "# Populate Fragmented\n",
                "with Session(engine) as session:\n",
                "    for data in clusters_data:\n",
                "        core = ClusterCore(\n",
                "            name=data[\"name\"], topic=data[\"topic\"], \n",
                "            image_url=data[\"image_url\"], is_private=data[\"is_private\"]\n",
                "        )\n",
                "        session.add(core)\n",
                "        session.flush()\n",
                "        \n",
                "        info = ClusterInfo(\n",
                "            cid=core.cid, description=data[\"description\"], \n",
                "            owner_id=data[\"owner_id\"], rules=data[\"rules\"], settings=data[\"settings\"]\n",
                "        )\n",
                "        stats = ClusterStats(\n",
                "            cid=core.cid, member_count=data[\"member_count\"], post_count=data[\"post_count\"]\n",
                "        )\n",
                "        session.add(info)\n",
                "        session.add(stats)\n",
                "    session.commit()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Benchmarks"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Benchmarking Discovery (List Scenario)...\")\n",
                "\n",
                "# Benchmark Discovery (List Names & Images)\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    # Monolith fetches everything\n",
                "    results = session.exec(select(ClusterMonolith).limit(100)).all()\n",
                "mono_list_time = time.perf_counter() - start_time\n",
                "\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    # Fragmented fetches only Core\n",
                "    results = session.exec(select(ClusterCore).limit(100)).all()\n",
                "frag_list_time = time.perf_counter() - start_time\n",
                "\n",
                "print(f\"Monolith List (100 items): {mono_list_time:.6f}s\")\n",
                "print(f\"Fragmented List (100 items): {frag_list_time:.6f}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Benchmarking Stats Update...\")\n",
                "\n",
                "# Benchmark Stats Update (Join Cluster)\n",
                "\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    # Get a valid CID for Monolith\n",
                "    cid_target = session.exec(select(ClusterMonolith.cid)).first()\n",
                "    cluster = session.exec(select(ClusterMonolith).where(ClusterMonolith.cid == cid_target)).first()\n",
                "    cluster.member_count += 1\n",
                "    session.add(cluster)\n",
                "    session.commit()\n",
                "mono_update_time = time.perf_counter() - start_time\n",
                "\n",
                "start_time = time.perf_counter()\n",
                "with Session(engine) as session:\n",
                "    # Get a valid CID for Fragmented\n",
                "    cid_target = session.exec(select(ClusterStats.cid)).first()\n",
                "    stats = session.exec(select(ClusterStats).where(ClusterStats.cid == cid_target)).first()\n",
                "    stats.member_count += 1\n",
                "    session.add(stats)\n",
                "    session.commit()\n",
                "frag_update_time = time.perf_counter() - start_time\n",
                "\n",
                "print(f\"Monolith Update: {mono_update_time:.6f}s\")\n",
                "print(f\"Fragmented Update: {frag_update_time:.6f}s\")\n",
                "\n",
                "ratio = mono_update_time / frag_update_time if frag_update_time > 0 else 0\n",
                "print(f\"\\nFragmented Update is {ratio:.2f}x faster than Monolith.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}